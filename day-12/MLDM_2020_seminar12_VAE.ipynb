{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM-2020-seminar12-VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2020/blob/master/day-12/MLDM_2020_seminar12_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtR3OYQSs6MC"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EY64ZjVtb_Q"
      },
      "source": [
        "lfw = tfds.image_classification.LFW()\n",
        "lfw.download_and_prepare()\n",
        "ds = lfw.as_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVzsU0rotPSK"
      },
      "source": [
        "def get_img(x):\n",
        "  return x['image'][80:-80,80:-80]\n",
        "\n",
        "data = np.array([\n",
        "  np.array(Image.fromarray(img.numpy()).resize((36, 36)))\n",
        "  for img in tqdm(ds['train'].map(get_img))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9p3GwjbtWxr"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz8KQmNDumG7"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6NuBd7cunql"
      },
      "source": [
        "plt.imshow(data[:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLbXtftPxEC5"
      },
      "source": [
        "X_train = data.astype('float32') / 255\n",
        "print(X_train.min(), X_train.max(), X_train.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_kNbCPnwjh8"
      },
      "source": [
        "ll = tf.keras.layers\n",
        "\n",
        "LATENT_DIM = 32\n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "  ll.Dense(128, input_shape=(LATENT_DIM,), activation='relu'),\n",
        "  ll.Dense(128, activation='relu'),\n",
        "  ll.Dense(36 * 36 * 3, activation='sigmoid'),\n",
        "  ll.Reshape((36, 36, 3)),\n",
        "])\n",
        "\n",
        "encoder_base = tf.keras.Sequential([\n",
        "  ll.Reshape((36 * 36 * 3,), input_shape=(36, 36, 3)),\n",
        "  ll.Dense(128, activation='relu'),\n",
        "  ll.Dense(128, activation='relu')\n",
        "])\n",
        "latent_mu = ll.Dense(LATENT_DIM, activation=None)(encoder_base.output)\n",
        "latent_logsigma = ll.Dense(LATENT_DIM, activation=None)(encoder_base.output)\n",
        "encoder = tf.keras.Model(inputs=encoder_base.inputs, outputs=[latent_mu, latent_logsigma])\n",
        "\n",
        "decoder.summary()\n",
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gxjEFhdx886"
      },
      "source": [
        "def gen_images(mu, logsigma):\n",
        "  return decoder(tf.random.normal(shape=mu.shape) * tf.exp(logsigma) + mu)\n",
        "\n",
        "# @tf.function decorator below compiles the function\n",
        "# it decorates into a static graph. This improves the performance\n",
        "# but there are some pitfalls one should be aware of when using it,\n",
        "# check out https://www.tensorflow.org/guide/function\n",
        "# for more details\n",
        "@tf.function\n",
        "def forward(batch):\n",
        "  real = batch\n",
        "\n",
        "  mu, logsigma = encoder(real)\n",
        "  fake = gen_images(mu, logsigma)\n",
        "\n",
        "  loss_mse = tf.reduce_sum((real - fake)**2, axis=(1, 2, 3))\n",
        "  loss_KL = tf.reduce_sum(-logsigma + 0.5 * (mu**2 + tf.exp(2 * logsigma) - 1), axis=1)\n",
        "  return tf.reduce_mean(loss_mse + 0.2 * loss_KL)\n",
        "\n",
        "opt_g = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def gen_step(batch):\n",
        "  with tf.GradientTape() as t:\n",
        "    g_loss = forward(batch)\n",
        "  grads = t.gradient(g_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
        "  opt_g.apply_gradients(zip(grads, encoder.trainable_variables + decoder.trainable_variables))\n",
        "  return g_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQKnxL0M0DfI"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZLclVcDzkFl"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "N_EPOCHS = 100\n",
        "\n",
        "losses = []\n",
        "for i_ep in range(N_EPOCHS):\n",
        "  shuffle_ids = np.random.choice(len(X_train), len(X_train), replace=False)\n",
        "  epoch_loss = 0\n",
        "  for i_img in trange(0, len(X_train), BATCH_SIZE):\n",
        "    batch = X_train[shuffle_ids][i_img:i_img + BATCH_SIZE]\n",
        "    epoch_loss += gen_step(batch).numpy() * len(batch)\n",
        "\n",
        "  epoch_loss /= len(X_train)\n",
        "  losses.append(epoch_loss)\n",
        "\n",
        "  opt_g.learning_rate.assign(opt_g.learning_rate * 0.99)\n",
        "\n",
        "  imgs = (gen_images(tf.zeros(shape=(25, LATENT_DIM)),\n",
        "                    tf.zeros(shape=(25, LATENT_DIM))).numpy() * 255).astype('uint8')\n",
        "  clear_output(wait=True)\n",
        "  plt.figure(figsize=(12, 7))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(imgs.reshape((5, 5, 36, 36, 3)).transpose(0, 2, 1, 3, 4).reshape(36 * 5, 36 * 5, 3))\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(losses)\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.show()\n",
        "  print(\"Done with epoch #\", i_ep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lltag3hx77ha"
      },
      "source": [
        "codes = encoder.predict(X_train)\n",
        "reco = decoder.predict(codes[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZktgBVrvWGS"
      },
      "source": [
        "shuffle_ids = np.random.choice(len(X_train), len(X_train), replace=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6), dpi=100)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(data[shuffle_ids][:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));\n",
        "plt.title('Train')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(reco[shuffle_ids][:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));\n",
        "plt.title('Reconstructed');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkVpkYcNvyxu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}