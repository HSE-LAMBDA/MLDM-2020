{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLDM-2020-seminar09-homework.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7ZGktFxlJ/mGBT3oblECD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2020/blob/master/day-09/MLDM_2020_seminar09_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un3T_AERfRG4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BphdyxaWjbWp"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "data_train = tfds.load(name=\"fashion_mnist\", split=\"train\").prefetch(60000).cache()\n",
        "data_test  = tfds.load(name=\"fashion_mnist\", split=\"test\" ).prefetch(10000).cache()\n",
        "\n",
        "# Array for decoding the categories\n",
        "label_names = np.array(['T-shirt/top',\n",
        "                        'Trouser',\n",
        "                        'Pullover',\n",
        "                        'Dress',\n",
        "                        'Coat',\n",
        "                        'Sandal',\n",
        "                        'Shirt',\n",
        "                        'Sneaker',\n",
        "                        'Bag',\n",
        "                        'Ankle boot'])\n",
        "\n",
        "# Get a single data batch of 25 images\n",
        "sample_data = next(iter(data_train.batch(25)))\n",
        "sample_images = sample_data['image']\n",
        "sample_labels = sample_data['label']\n",
        "\n",
        "# Plot the images in a 5x5 grid\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(\n",
        "    sample_images.numpy().reshape(5, 5, 28, 28).transpose((0, 2, 1, 3)).reshape(140, 140),\n",
        "    cmap='gray'\n",
        ")\n",
        "# Print corresponding labels\n",
        "print(label_names[sample_labels.numpy().reshape(5, 5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6K2SAJdkQHm"
      },
      "source": [
        "# Task 1 (5 points + 1 point for the short comment)\n",
        "\n",
        "Fill the gaps below to build a convolutional neural network and classify the images. Write a short comment on the validation metric images that you should obtain in the last cell.\n",
        "\n",
        "Some hints for classes:\n",
        " - `tf.keras.layers.Conv2D` - convolutional layer\n",
        " - `tf.keras.layers.MaxPool2D` - maxpool layer\n",
        " - `tf.keras.layers.BatchNormalization` - batchnorm layer\n",
        " - `tf.keras.layers.Dropout` - dropout layer\n",
        " - `tf.keras.layers.Reshape` - reshaping layer (to convert the image-like representation to a vector-like representation deep down in the network\n",
        "\n",
        "Try to follow the general deep convolutional architecture:\n",
        " - combine convolutions with maxpoolings to reduce the spacial size of the representation\n",
        " - increase the number of filters as you go deeper\n",
        " - when the spacial size of your representation is small enough (1-2 pixels), convert (reshape) it to a vector and then use fully connected layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpJ6rBBIXZPt"
      },
      "source": [
        "As you do this task, try to answer the following questions to yourself:\n",
        " - should I place batchnorm before or after the activation function?\n",
        "  - (to answer this one, think how inactive neurons would affect the batchnorm statistics)\n",
        " - should I add dropout before or after batchnorm?\n",
        "  - (think how batchnorm and dropout might interfere)\n",
        " - do I need an activation for the output layer?\n",
        "  - (check the loss function used)\n",
        " - does it make sense to add a dropout to the output layer?\n",
        "  - (common sense)\n",
        " - is it a good idea to add a batchnorm to the output layer?\n",
        "  - (in fact, I don't have a good answer to this one, but imo a batchnorm in the last layer might lead to weird effects)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir0hafMrjgNY"
      },
      "source": [
        "def build_model(use_batchnorm=False, dropout_rate=0.):\n",
        "  \"\"\"\n",
        "  Fill in the layers below.\n",
        "\n",
        "  If use_batchnorm is True, add a batchnorm layer to **every** convolution and\n",
        "  dense layer (except for the output one).\n",
        "  If dropout_rate > 0, add a dropout layer with `rate=dropout_rate` to **every**\n",
        "  convolution and dense layer (except for the output one).\n",
        "  \"\"\"\n",
        "  layers = []\n",
        "\n",
        "  layers.append(<YOUR CODE>)\n",
        "  if use_batchnorm: layers.append(<YOUR CODE>)\n",
        "  <YOUR CODE>\n",
        "\n",
        "  model = tf.keras.Sequential(layers)\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHG2vJcDakw5"
      },
      "source": [
        "The code below creates and trains a bunch of models, then plots their validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXrE2XSaEAwE"
      },
      "source": [
        "configs = [\n",
        "  dict(use_batchnorm=False, dropout_rate=0),\n",
        "  dict(use_batchnorm=False, dropout_rate=0.01),\n",
        "  dict(use_batchnorm=False, dropout_rate=0.05),\n",
        "  dict(use_batchnorm=False, dropout_rate=0.5),\n",
        "  dict(use_batchnorm=True, dropout_rate=0),\n",
        "  dict(use_batchnorm=True, dropout_rate=0.01),\n",
        "  dict(use_batchnorm=True, dropout_rate=0.05),\n",
        "  dict(use_batchnorm=True, dropout_rate=0.5),\n",
        "]\n",
        "\n",
        "models = {str(config) : build_model(**config) for config in configs}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pxRcezOILTn"
      },
      "source": [
        "batch_size = 512\n",
        "\n",
        "def preprocess(x):\n",
        "  return (tf.cast(x['image'], 'float32') / 255., x['label'])\n",
        "\n",
        "for config, model in models.items():\n",
        "  print(\"Working on model:\", config)\n",
        "  model.fit(x=data_train.map(preprocess).shuffle(60000).batch(batch_size), epochs=10,\n",
        "            validation_data=data_test.map(preprocess).batch(4096))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmAqM7dbIa48"
      },
      "source": [
        "plt.figure(figsize=(6, 8), dpi=100)\n",
        "color_cycle = iter(plt.rcParams['axes.prop_cycle'])\n",
        "\n",
        "colors = {}\n",
        "\n",
        "lines = []\n",
        "labels = []\n",
        "for config, model in models.items():\n",
        "  config = eval(config)\n",
        "  if config['dropout_rate'] not in colors:\n",
        "    colors[config['dropout_rate']] = next(color_cycle)\n",
        "\n",
        "  color = colors[config['dropout_rate']]['color']\n",
        "\n",
        "  style = '-' if config['use_batchnorm'] else '--'\n",
        "  line, = plt.plot(model.history.history['val_sparse_categorical_accuracy'], style,\n",
        "                   c=color)\n",
        "  \n",
        "  if config['use_batchnorm']:\n",
        "    lines.append(line)\n",
        "    labels.append(f\"do_rate = {config['dropout_rate']}\")\n",
        "\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"test accuracy\");\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "lines += [Line2D([0], [0], linestyle='-', color='w'),\n",
        "          Line2D([0], [0], linestyle='-', color='k'),\n",
        "          Line2D([0], [0], linestyle='--', color='k')]\n",
        "labels += ['', 'batchnorm on', 'batchnorm off']\n",
        "plt.legend(lines, labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NluyJb7Sbaas"
      },
      "source": [
        "\\<YOUR SHORT COMMENT GOES HERE\\>"
      ]
    }
  ]
}